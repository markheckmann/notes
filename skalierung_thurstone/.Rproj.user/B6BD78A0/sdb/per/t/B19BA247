{
    "contents" : "Thurstone Scaling\n===============\n\n```{r echo=FALSE, message=FALSE, warning=FALSE, fig.height=4}\nlibrary(car)\nlibrary(reshape2)\nlibrary(ggplot2)\n```\n\n## Methode des paarweisen Vergleichs (Law of Comparative Judgement [LCJ])\n\n```{r echo=FALSE, results='hide'}\nm <- matrix(c(.5, .07, .76, .0, .1, .79, 1.0,\n         .93, .5, 1.0, .21, .65, .97, .97,\n         .24, .0, .5, .03, .03, .41, .93,\n        1.0, .79, .97, .5, .93, 1.0, 1.0,\n         .9, .35, .97, .07, .5, .93, 1.0,\n         .21, .03, .59, .0, .07, .5, .97,\n         .0, .03, .07, .0, .0, .03, .5), ncol=7, byrow=T)\nnms <- c(\"Alkohol\", \"Ecstasy\", \"Hanf\", \"Heroin\", \"Kokain\", \"Nikotin\", \"Kaffee\")\ncolnames(m) <- nms\nrownames(m) <- nms\nm\n```\n\nZwei Objekte i und j werden beurteilt. Der Urteiler urteilt nicht jedes Mal exakt. Die Urteile variieren um die wahren Skalenwerte $s_i$ und $s_j$.\n\n```{r echo=FALSE, fig.height=4}\nn <- 1e4\ns.i <- 1\ns.j <- 2.5\ns.i.sd <- .5\ns.j.sd <- .5\ni <- rnorm(n, mean=s.i, sd=s.i.sd)\nj <- rnorm(n, mean=s.j, sd=s.j.sd)\nd <- i - j\nhist(i, breaks=50, prob=T, xlim=range(i,j), xlab=\"Urteilsdimension\", \n     ylab=\"\", col=NA, border=\"blue\", main=\"Beurteilung von zwei Objekte\")\nhist(j, breaks=50, prob=T, add=T, col=NA, border=\"red\")\ncurve(dnorm(x, mean=mean(i), sd=sd(i)), add=TRUE, col=\"blue\") \ncurve(dnorm(x, mean=mean(j), sd=sd(j)), add=TRUE, col=\"red\") \nabline(v=c(s.i, s.j), col=c(\"blue\", \"red\"), lwd=3)\nmtext(\"s_i\", 1, line=1.7, at=s.i, col=\"blue\")\nmtext(\"s_j\", 1, line=1.7, at=s.j, col=\"red\")\n```\n\nIn dem Bild gilt die Beziehung $s_i > s_j$. Das Objekt $i$ hat auf der Urteilsdimension einen geringeren wahren Wert als das Objekt $j$. Die Beurteilung des Objektes enthält jedoch ein zufällige Feghlerkomponente. Die realen i und j Werte schwanken normalverteilt um den die wahren Werte $s_i$ und $s_j$. Wie wahrscheinlich ist es nun, dass sich bei der Beureteilung, bedingt durch den zufälligen Fehler, die Reihenfolge der Objekte auf der Dimension umkehrt? Hierzu wird die Verteilung der Differenzen der Urteile betrachtet. Die Differenz sei $d=s_i > s_j$.\nDie Verteilung der Differenzen ist nachfolgend dargestellt. \n\n```{r echo=FALSE, fig.height=4, warning=FALSE}\nh <- hist(d, breaks=50, prob=T)\ncols <- recode(h$mids, \"lo:0=NA; else='red'\")\nh <- hist(d, breaks=50, prob=T, border=cols, col=cols, add=T)\ncurve(dnorm(x, mean=mean(d), sd=sd(d)), add=TRUE, col=\"blue\") \nabline(v=s.i-s.j, col=\"red\", lwd=2)\n\n#sd.d <- ( sd(i)^2 + sd(j)^2 - cor(i, j) * sd(i)* sd(j) )^.5\n\n```\n\nDer Erwartungswert (die wahre Differenz zwischen den Objekten) entspricht \n$s_i - s_j=$ `r s.i - s.j`. \nDie Streuung der Differenzen ist: \n$\\sigma_{ij} = \\sqrt{\\sigma_i^2 + \\sigma_j^2 -2r_{ij}\\sigma_i \\sigma_j}$.\n\nStandardisierung der Differenzen:\n$z_{ij}\n=\\frac{0-(s_i-s_j)}{\\sigma_{ij}}\n=\\frac{s_j - s_i}{\\sigma_{ij}}$.\n\nAnnahmen:\n\n* Die Urteile streuen bei jedem Objekt im gleichen Ausmaß um den wahren Wert, d.h. die Streuungen sind identisch.\n$\\sigma_i^2 = \\sigma_j^2$\n* Die Korrelation der Urteile zwischen den Objekten ist konstant.\n$r_{ij} =r_{ik}$\n\nUnter Einbeziehung der Annahmen vereinfacht sich die Streuung der Urteilsdifferenzen zu\n$z_{ij}\n=\\frac{s_j - s_i}{\\sigma^2 + \\sigma^2 - 2r\\sigma^2}\n=\\frac{s_j - s_i}{2\\sigma^2 (1-r)}$.\n\nEs zeigt sich, dass der Nenner für alle Paarvergleiche einen konstanten Wert annimmt. D.h. es handelt sich stest um die gleiche konstante lineare Transformation für jeden Paarvergleich. Aus diesem Grund kann der Nenner ohne Informationsverlust durch einen beliebigen anderen konstanten Wert ersetzt werden, z.B. den Wert $1$. Zwar ändert sich hierbei der absolute Wert, nicht jedoch die Relationen der Werte. Diese von Thurstone eingeführte Vereinfachung wird als *CASE V* bezeichnet. In Folge vereinfacht sich die Differenz der Urteile zu\n$z{ij} = s_j - s_i$\n\n### Vorgehensweise\n\nGegeben sei folgende Auszählung an der Dominanzurteile.\nDas Spaltenmerkmal dominiert das Zeilenmerkmal.\n\n```{r echo=FALSE}\nP <- m\nP * 100\n```\n\nEs werden nun für jeden Vergleich die relative Häufigkeit für das Auftreten des \nDominanzurteils berechnet.\n\n```{r echo=FALSE}\nP\n```\n\nDie relativen Häufigkeiten werden nun in die zugehörigen z-Werte umgewandelt.\nDie P-Werte $0$ und $1$ Werte haben als korrespondierende z-Werte -/+ Inf. \nAus diesem Grund werden diese Werte hier mit $.01$ bzw. $.99$ substituiert, \num nutzbare z-Werte zu erhalten.\n\n```{r echo=FALSE}\nz <- P\nz[z == 0] <- .01 \nz[z == 1] <- .99\nz <- t(apply(z, 1, qnorm))\n#mz <- mz[, -ncol(mz)]\nround(z, 2)\n```\n\nDie z-Werte werden nun zeilenweise gemittelt (Spalte z.mean).\nAnschließend wird der Nullpunkt der Skala auf den kleinsten Werte gesetzt, \nd.h. der kleinste Wert wird abgezogen (Spalte s.i). Diese Werte bilden die $s_i$, \nd.h. die Werte der Objekte auf dem Beurteilungskontinuum.\n\n```{r echo=FALSE}\nz.mean <- rowMeans(z)\ns.i <- z.mean - min(z.mean)\nres <- cbind(z.mean, s.i)\nround(res, 2)\n```\n\nKaffee wird als am ungefährlichsten, Heroin als am gefährlichsten eingestuft.\nDer Unterschied zwischen Kaffee und Alkohol (`r round(abs(z.mean[1] - z.mean[7]), 2)`) entspricht in etwa dem von Alkohol \nund Heroin (`r round(abs(z.mean[1] - z.mean[4]), 2)`).\n\n\n**Rekonstruktion der P-Werte**\n\nIm Folgenden werden die P-Werte aus den Skalenwerten rekonstruiert. Dies dient dazu, die Güte der Reproduktion zu beurteilen.\n\nFür jedes Stimuluspaar wird die Differenz der $s_i$ Werte berechnet. Dies entspricht den rekonstruierten z-Werten $z'$.\n\n```{r echo=FALSE}\nz.repro <- z.mean - t(replicate(length(z.mean), z.mean))\nrownames(z.repro) <- colnames(z.repro)\nround(z.repro, 2)\n```\n\nDie z-Werte stellen die Quartile der Bormalverteilung dar. Die zugehörigen Wahrscheinlichkeiten können aus der NV-Tabelle abgelesen werden.\n\n```{r echo=FALSE}\nP.repro <- pnorm(z.repro)\nround(P.repro, 2)\n```\n\nUm die Güte der Reprduktion zu beurteilen wird elementweise die absoluten Differenz zwischen der beiden P-Matrizen gebildet.\n\n```{r echo=FALSE}\nd <- abs(P - P.repro)\nround(d, 2)\n```\n\nDer durchschnittliche absolute Differenz wird als Indikator für die Güte des Modells genutzt.\nDer Wert sollte unter $.03$.\n\n```{r echo=FALSE}\nad <- mean(d[lower.tri(d)])\nround(ad, 2)\n```\n\nDas Modell weist somit eine mittelmäßige Anpassung auf.\n\n\n\n******\n\n## Methode der sukzessiven Intervalle (Method of Succesive Intervals [MIS])\n\n\n### Theorie\n\n**Ziel:**  Information über den Abstand der Objekte (intervallskaliert)\n\n**Annahmen:** (Thurstone, 1927)\n* Urteiler kann Merkmalskontinuum in Kategorien aufteilen.\n* Kategoriengrenzen schwanken um wahren Wert.\n* Wahrscheinlichkeit für Realisierung einer Kategoriengrenze ist normalverteilt.\n* Beurteilung einer Merkmalsausprägung schwankt ebenfalls zufällig.\n* Wahrscheinlichkeit für Realisierung eines Urteils auch normalverteilt.\n* Urteiler stuft Reiz unterhalb Kategoriengrenze ein, wenn die im Urteil realisierte Merkmalsausprägung des Reizes geringer ist als die durch die realisierte Kategoriengrenze repräsentierte Merkmalsausprägung.\n\n### Simulation\n\n```{r echo=FALSE, results='hide'}\n# Berechnung der Kategorie und Objekt Parameter auf Basis\n# einer Kontingenztabelle:\n# Zeilen: Objekte\n# Spalten: Kategorien der Ratingskala\n#\nthurstone_msi <- function(m.f)\n{\n  m.h <- m.f/rowSums(m.f)           # relative Häufigkeiten\n  m.H <- t(apply(m.h, 1, cumsum))   # Zeilenweise kumulierte relative Häufigkeiten\n  m.H[m.H == 0] <- .0001            # Ersetzen der 0 und 1 Werte\n  m.H[m.H == 1] <- .9999\n  m.z <- t(apply(m.H, 1, qnorm))\n  m.z <- m.z[, -ncol(m.z)]\n  SM <- colMeans(m.z)               # Mittelwert der Kategorienwerte\n  ZM <- rowMeans(m.z)               # Mittelwert der Objektwerte\n  s.j <- mean(SM) - ZM              # Mittel der Kategorien - Objektwerte\n  s.j0 <- s.j - min(s.j)            # Skala bei Null verankern\n  list(categories=SM, objects=s.j, objects.0=s.j0)  \n}\n```\n\n**Ausgangsdaten**\n\n```{r echo=FALSE}\nrows <- c(\"Alkohol\", \"Ecstasy\", \"Hanf\", \"Heroin\", \"Kokain\", \"Nikotin\", \"Kaffee\")\nm.f <- matrix(c(0, 0, 7, 6, 10, 1, 5,  \n         0, 0, 2, 0, 2, 5, 20,\n         0, 4, 9, 2, 10, 4, 0,\n         0, 0, 0, 0, 1, 2, 26,\n         0, 0, 1, 0, 2, 7, 19,\n         0, 0, 4, 7, 15, 2, 1,\n         4, 14, 9, 1, 1, 0, 0), ncol=7, byrow=TRUE)\nrownames(m.f) <- rows\ncolnames(m.f) <- paste0(\"K\", 1:7)\nm.f\n```\n\n**Parameterschätzungen**\n\n```{r echo=FALSE}\nl <- thurstone_msi(m.f)\nl\n```\n\n\n**Simulation von Daten auf Basis der Parameter**\n\n```{r echo=FALSE, message=FALSE, warning=FALSE, fig.height=4}\n\n### Simulation ###\n\n# Ratings für alle Objekte in abhängigkeit von den wahren \n# Objekt- und Kategoriegrenzen sowie den zugehörigen Standardabweichungen.\n#\nratings_one_sample <- function(o.l, c.l, sd.o, sd.c)\n{\n  o.l.sim <- rnorm(length(o.l), mean=o.l, sd=sd.o)    # generate random values based on true object locations\n  c.l.sim <- rnorm(length(c.l), mean=c.l, sd=sd.c)    # generate random category breaks\n  x <- as.numeric(cut(o.l.sim, breaks=c(-Inf, c.l.sim, Inf)))\n  names(x) <- names(o.l)\n  x\n}\n```\n\n**Simulierte Daten**\n\n```{r echo=FALSE}\n# Konkrete Simulation. Ausgangsdaten sind die Parameter der Beispieldaten\nl <- thurstone_msi(m.f)\nn <- 100\no.l <- l$objects      # Objektlokationen\nc.l <- l$categories   # Lokationen Kategoriegrenzen  \nncat <- length(c.l)\nsd.o <- .5            # Streuung der Objekturteile\nsd.c <- .5            # Streuung der Kategorieurteile\nx <- replicate(n, ratings_one_sample(o.l, c.l, sd.o, sd.c))  # Ratings für n Beurteiler\nxa <- t(apply(x, 1, tabulate, nbin=length(c.l) + 1))\ncolnames(xa) <- paste0(\"K\", 1:(length(c.l) + 1))\nxa\n```\n\n**Dichteverteilung der Ratings**\n\n```{r echo=FALSE, fig.height=4}\nx.long <- melt(x)\nggplot(x.long, aes(x=value, fill=Var1)) + \n  geom_density(adjust=2, alpha=.3) + \n  scale_x_continuous(breaks=1:7, labels=1:7, name=\"Kategorien\")\n```\n\n**Schätzungen der Parameter**\n\n```{r echo=FALSE}\n#thurstone_msi(m.f)\nthurstone_msi(xa)\n```\n\n\n\n\n### Test\n\nAus Gerich (). Thurstone- und Likertskalierung, 20XX).\n\nGefährlichkeitsbewertung verschiedener Substanzen auf einer Ratingskala von 1 bis 7 von 1=völlig ungefährlich, 7=sehr gefährlich).\n\n```{r echo=FALSE}\nm.f\n```\n\n\n```{r echo=FALSE, results='hide'}\n#Berechnen wir die relativen Häufigkeiten.\nm.h <- m.f/rowSums(m.f)\nround(m.h, 2)\n```\n\nZeilenweise kumulierte relative Häufigkeiten\n\n```{r echo=FALSE}\nm.H <- t(apply(m.h, 1, cumsum))\nround(m.H, 2)\n```\n\nZur Häufigkeit gehörige z-Werte. Die Verteilung der Ratings wird als NV um den wahren Wert angenommen. Die P-Werte 0 und 1 Werte haben als korrespondierende z-Werte -/+ Inf. Aus diesem Grund werden diese Werte hier mit 0.0001 bzw. .9999 substituiert, um nutzbare z-Werte zu erhalten. Die letzte Kategorie liefert keine zur Skalierung nutzbaren Informationen, da Sie für jede Kategorie $P=1$ beträgt. Sie wird deshalb ausgelassen.\n\n```{r echo=FALSE}\nm.H[m.H == 0] <- .0001 \nm.H[m.H == 1] <- .9999\nm.z <- t(apply(m.H, 1, qnorm))\nm.z <- m.z[, -ncol(m.z)]\nround(m.z, 2)\n```\n\nDie Lokation der Kategoriegrenzen ergibt sich durch die spaltenweise Mittelung der z-Werte.\n\n```{r echo=FALSE}\nSM <- colMeans(m.z)\nround(SM, 2)\n```\n\nDie Werte für die beurteilten Objekte ergeben sich als Zeilenmittel.\n\n```{r echo=FALSE}\nZM <- rowMeans(m.z)\nround(ZM, 2)\n```\n\nAls letzte Schritt wird von dem Mittel der Kategorielokationen die Objektlokationen abgezogen.\n\n```{r echo=FALSE}\ns.j <- mean(SM) - ZM\nround(s.j, 2)\n```\n\n**Test**\n```{r}\nthurstone_msi(m.f)\n```\n\n\n**Skalenwerte und Objektwerte auf dem Merkmalskontinuum**\n\n```{r echo=FALSE}\ncex <- 1\nplot(cbind(1, c(SM, s.j)), type=\"n\", xlim=c(0,2), xlab=\"\", ylab=\"\", \n     xaxt=\"n\", yaxt=\"n\", frame=F)\nabline(v=1)\nsegments(.7, SM, 1, SM, col=\"blue\")\ntext(.7, SM, labels=names(SM), pos=2, cex=cex, col=\"blue\")\nsegments(1, s.j, 1.3, s.j, col=\"red\")\ntext(1.3, s.j, labels=names(s.j), pos=4, cex=cex, col=\"red\")\n```\n\n\n### Beispiel II\n\nFünf Therapieprotokoll A-E sollen in Bezug auf das Merkmalskontinuum emotional Wärme skaliert werden. Hierzu liegen die Urteile von $n=50$ Probanden auf einer Ordinalskala vor. Diese lautet wie folgt: 1= \"sehr viel\", 2=\"viel\", 3=\"neutral\", 4=\"wenig\", 5=\"gar nicht\".\nDas Ergebnis ist folgende Kontingenztabelle.\n\n```{r echo=FALSE}\nm.f <- matrix(c(2,8,10,13,17,\n              5,10,15,18,2,\n              10,12,20,5,3,\n              15,20,10,3,2,\n              22,18,7,2,1), byrow=T, ncol=5)\nm.f\n```\n\nBerechnen wir die relativen Häufigkeiten.\n\n```{r echo=FALSE}\nm.h <- m.f/rowSums(m.f)\nm.h\n```\n\nKumulierte relative Häufigkeiten\n\n```{r echo=FALSE}\nm.H <- t(apply(m.h, 1, cumsum))\nm.H\n```\n\nThurstone macht die Annahme NV.\n\n```{r echo=FALSE}\nm.z <- t(apply(m.H, 1, qnorm))\nm.z[m.z == Inf] <- 1\nm.z <- m.z[, -ncol(m.z)]\nm.z\n```\n\nSpaltensummen und Sapltenmittel\n\n```{r echo=FALSE}\nSS <- colSums(m.z)\nSM <- colMeans(m.z)\nm.z.s <- rbind(m.z, SS, SM)\n```\n\nZeilensummen und Zeilenmittel\n\n```{r echo=FALSE}\nZS <- rowSums(m.z.s)\nZM <- rowMeans(m.z.s)\nm.z.sz <- cbind(m.z.s,  ZS, ZM)\nm.z.sz\n```\n\nDurchschnitt Kategoriengrenze\n\n```{r echo=FALSE}\nMK <- mean(SM)\nMK\nMA <- ZM - MK \nm <- cbind(m.z.sz, MA)\nm\n```\n\nLineare Transformation, um einen künstlichen Nullpunkt zu konstruieren.\n\n```{r}\nMA\n#MA <- MA + abs(min(MA))\n#MA\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "created" : 1358769332319.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "608108985",
    "id" : "B19BA247",
    "lastKnownWriteTime" : 1359497743,
    "path" : "~/Documents/_mh/uni/teaching/collecting_r/ml/R/scaling_thurstone.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}